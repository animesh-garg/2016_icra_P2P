\section{Visual Featurization}

\todo{fill in}
\begin{enumerate}
\item Describe goals

\begin{enumerate}
\item Spatially \& Scale invariant features
\item Key in on primitives
\end{enumerate}

\item Describe different ways that you can get visual features
\begin{enumerate}
\item Deep features from Convolutional Neural Networks
\item Pre-trained models from CAFFE - vanilla AlexNet (Krizevksy et al.)
\item Pre-trained models from CAFFE - VGG (Simonyan and Zisserman)
\item Encoding (Doesn't really work now)
\item SIFT/SURF (Lowe)
\item Dense Trajectories (Heng Wang)
\end{enumerate}

\item Describe what we did and our methodology

\item Pre-processing
\begin{itemize}
\item Background subtraction
\begin{itemize}
\item A OpenCV built-in background subtraction algorithm was applied on each frame before pushing through the CNN. The algorithm was a Gaussian Mixture-based Background/Foreground Segmentation algorithm. It was introduced in the paper "An improved adaptive background mixture model for real-time tracking with shadow detection" by P. KadewTraKuPong and R. Bowden in 2001.
\end{itemize}

\item Cropping \& Scaling
\begin{itemize}
\item I cropped all frames by equal amounts to capture only the workspace where most of the robot manipulation happened. Then, they were rescaled to 640 x 480 dimensions. All pre-processing happened with ffmpeg.
\end{itemize}

\end{itemize}


\end{enumerate}